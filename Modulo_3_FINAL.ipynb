{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/esteban-miller/3.Transformacion-modelado-de-datos/blob/main/Modulo_3_FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "VRiYrjmodXmf",
        "collapsed": true,
        "outputId": "4653bb19-0e22-4e38-d9bf-2f6e383fe41a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/235.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m225.3/235.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.8\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'barcelona.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-4a358d779bb6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0marchivos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'barcelona.xlsx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'valencia.xlsx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pozuelo.xlsx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mallorca.xlsx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'malasaña.xlsx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtabla_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchivo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marchivo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marchivos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#df_barcelona = pd.read_excel(\"C:/Users/jaque/Documents/IMMUNE/Modulo3/Ejercicio Final/barcelona.xlsx\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-4a358d779bb6>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0marchivos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'barcelona.xlsx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'valencia.xlsx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pozuelo.xlsx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mallorca.xlsx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'malasaña.xlsx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtabla_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchivo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marchivo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marchivos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#df_barcelona = pd.read_excel(\"C:/Users/jaque/Documents/IMMUNE/Modulo3/Ejercicio Final/barcelona.xlsx\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1551\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'barcelona.xlsx'"
          ]
        }
      ],
      "source": [
        "# Intergrantes:\n",
        "#\n",
        "# Sergio Martin\n",
        "# Esteban Miller\n",
        "# Jaquelin Da Costa\n",
        "# Roberto De Gouveia\n",
        "\n",
        "!pip install unidecode\n",
        "\n",
        "import pandas as pd\n",
        "from unidecode import unidecode\n",
        "\n",
        "# Cargar datos\n",
        "archivos = ['barcelona.xlsx', 'valencia.xlsx', 'pozuelo.xlsx', 'mallorca.xlsx', 'malasaña.xlsx']\n",
        "\n",
        "tabla_total = pd.concat([pd.read_excel(archivo) for archivo in archivos])\n",
        "\n",
        "#df_barcelona = pd.read_excel(\"C:/Users/jaque/Documents/IMMUNE/Modulo3/Ejercicio Final/barcelona.xlsx\")\n",
        "#df_malasana = pd.read_excel(\"C:/Users/jaque/Documents/IMMUNE/Modulo3/Ejercicio Final/malasaña.xlsx\")\n",
        "#df_mallorca = pd.read_excel(\"C:/Users/jaque/Documents/IMMUNE/Modulo3/Ejercicio Final/mallorca.xlsx\")\n",
        "#df_pozuelo = pd.read_excel(\"C:/Users/jaque/Documents/IMMUNE/Modulo3/Ejercicio Final/pozuelo.xlsx\")\n",
        "#df_valencia = pd.read_excel(\"C:/Users/jaque/Documents/IMMUNE/Modulo3/Ejercicio Final/valencia.xlsx\")\n",
        "#\n",
        "#tabla_total = pd.concat([df_barcelona,df_malasana,df_mallorca,df_pozuelo,df_valencia], ignore_index=True)\n",
        "#tabla_total = pd.read_excel(\"C:/Users/jaque/Documents/IMMUNE/Modulo3/Ejercicio Final/barcelona.xlsx\")\n",
        "\n",
        "#Información general de la tabla\n",
        "tabla_total.dtypes\n",
        "tabla_total.size\n",
        "tabla_total.columns\n",
        "tabla_total.info()\n",
        "tabla_total.isnull().sum()\n",
        "x = tabla_total.describe()\n",
        "\n",
        "# Convertimos todo a minuscula y limpiamos antes y despues\n",
        "tabla_total.columns= tabla_total.columns.str.lower().str.strip()\n",
        "\n",
        "# Quitamos todos los caracteres diacriticos\n",
        "tabla_total.columns = [unidecode(col) for col in tabla_total.columns]\n",
        "\n",
        "#Nos percatamos de que hay columnas que tienen todos los datos nulos.\n",
        "\n",
        "# =============================================================================\n",
        "# VALORES NULOS\n",
        "# =============================================================================\n",
        "\n",
        "# Iterar y eliminar filas con número y fecha nulos\n",
        "for index, row in tabla_total.iterrows():\n",
        "    if pd.isnull(row['numero']) and pd.isnull(row['fecha']):\n",
        "        tabla_total.drop(index, inplace=True)\n",
        "\n",
        "# Cuantos valores nulos hay de cada variable\n",
        "tabla_total['familia'].fillna(\"NO INFO\", inplace = True)\n",
        "\n",
        "#Quitamos el check de \"Local\"\n",
        "tabla_total.local = tabla_total.local.str[:-4]\n",
        "\n",
        "#Tabla copia para hacer pruebas en el dataset original\n",
        "tabla_copia = tabla_total.copy()\n",
        "\n",
        "# Eliminamos las columnas que tienen todos los valores nulos,\n",
        "# cod. promocion, cod. descuento, grupo mayor\n",
        "tabla_total.isnull().sum()\n",
        "tabla_total.columns[tabla_total.isnull().any()]\n",
        "\n",
        "tabla_total.drop([\"cod. promocion\", \"grupo mayor\", \"cif\", \"cuenta contable\", \"ciudad\", \"provincia\", \"calle\", \"codigo postal\"], axis=1, inplace=True)\n",
        "\n",
        "# =============================================================================\n",
        "# Proyecto Final / Proyecto de Análisis de Ventas\n",
        "# =============================================================================\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Preguntas de Análisis:\n",
        "# =============================================================================\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# 1. Análisis Temporal:\n",
        "# =============================================================================\n",
        "# =============================================================================\n",
        "# ¿Cuál es el patrón temporal de las ventas en Barcelona, Valencia, Pozuelo,\n",
        "# Mallorca y Malasaña a lo largo de los días y año?\n",
        "# =============================================================================\n",
        "\n",
        "# Asegurar que la columna 'fecha' esté en formato datetime\n",
        "tabla_total['fecha'] = pd.to_datetime(tabla_total['fecha'], errors='coerce')\n",
        "\n",
        "# Extraer características temporales\n",
        "tabla_total['year'] = tabla_total['fecha'].dt.year\n",
        "tabla_total['month'] = tabla_total['fecha'].dt.month\n",
        "tabla_total['day_of_week'] = tabla_total['fecha'].dt.day_name()\n",
        "\n",
        "# Resumen de ventas por día\n",
        "resumen_diario = tabla_total.groupby([tabla_total['fecha'].dt.date, 'local'])['total'].sum().reset_index()\n",
        "\n",
        "# Resumen mensual\n",
        "resumen_mensual = tabla_total.groupby(['year', 'month','local'])['total'].sum().reset_index()\n",
        "\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# ¿Existen variaciones estacionales o eventos especiales que impacten\n",
        "# significativamente las ventas en cada ubicación?\n",
        "# =============================================================================\n",
        "\n",
        "#Realizamos una segmentacion por estaciones dividiendo por le numero del mes\n",
        "\n",
        "resumen_mensual[\"estaciones\"] =pd.cut(resumen_mensual.month,bins=[0,3,6,8,12],\n",
        "                               labels=[\"invierno\",\"primavera\",\"verano\",\"otoño\"])\n",
        "\n",
        "#Agrupamos y sumamos todos los totales por mes, año y local\n",
        "resumen_anual = resumen_mensual.groupby(['year','estaciones','local'])['total'].sum().reset_index()\n",
        "\n",
        "# =============================================================================\n",
        "# 2. Análisis Geográfico:\n",
        "# =============================================================================\n",
        "# =============================================================================\n",
        "# ¿Cómo se comparan las ventas totales y promedios entre las cinco\n",
        "# ubicaciones?\n",
        "# =============================================================================\n",
        "\n",
        "# Agrupé los datos por 'ubicacion' y calculé las ventas totales y el promedio\n",
        "resumen_ventas = tabla_total.groupby('ubicacion').agg(\n",
        "    ventas_totales=('total', 'sum'),\n",
        "    ventas_promedio=('total', 'mean')\n",
        ").reset_index()\n",
        "\n",
        "# =============================================================================\n",
        "# ¿Cuál es la distribución de clientes y cuáles son los productos más\n",
        "# populares en cada ubicación?\n",
        "# =============================================================================\n",
        "\n",
        "# Contar el número de clientes únicos en cada ubicación\n",
        "clientes_por_ubicacion = tabla_total.groupby('ubicacion')['cliente'].nunique().reset_index().rename(columns={'cliente': 'num_clientes'})\n",
        "\n",
        "# Busqué los productos más populares en cada ubicación\n",
        "productos_populares = tabla_total.groupby(['ubicacion', 'producto']).size().reset_index(name='frecuencia')\n",
        "productos_populares = productos_populares.sort_values(by=['ubicacion', 'frecuencia'], ascending=[True, False])\n",
        "\n",
        "# Obtuve el producto más popular en cada ubicación\n",
        "productos_mas_populares = productos_populares.loc[productos_populares.groupby('ubicacion')['frecuencia'].idxmax()]\n",
        "\n",
        "# =============================================================================\n",
        "# 3. Análisis de Descuentos:\n",
        "# =============================================================================\n",
        "# =============================================================================\n",
        "# ¿Cómo afectan los descuentos al aumento de las ventas en cada ubicación?\n",
        "# =============================================================================\n",
        "\n",
        "# Calculo del total de ventas sin descuento y con descuento\n",
        "tabla_total['ventas_sin_dto'] = tabla_total['cantidad'] * tabla_total['precio']\n",
        "tabla_total['ventas_con_dto'] = tabla_total['ventas_sin_dto'] - tabla_total['dto. eur']\n",
        "\n",
        "# Ubicación y calculo de las ventas totales sin descuento y con descuento agrupadas\n",
        "ventas_por_ubicacion = tabla_total.groupby('ubicacion').agg(\n",
        "    ventas_totales_sin_dto=('ventas_sin_dto', 'sum'),\n",
        "    ventas_totales_con_dto=('ventas_con_dto', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "# Impacto del descuento en las ventas\n",
        "ventas_por_ubicacion['impacto_descuento'] = ventas_por_ubicacion['ventas_totales_con_dto'] / ventas_por_ubicacion['ventas_totales_sin_dto'] - 1\n",
        "\n",
        "# =============================================================================\n",
        "# ¿Cuáles son los tipos de descuentos más utilizados y cuál es su impacto en\n",
        "#  los ingresos?\n",
        "# =============================================================================\n",
        "\n",
        "# Identificar los tipos de descuentos más utilizados\n",
        "tipos_descuentos_utilizados = tabla_total.groupby('cod. descuento').size().reset_index(name='frecuencia').sort_values(by='frecuencia', ascending=False)\n",
        "\n",
        "impacto_descuentos = tabla_total.groupby('cod. descuento').agg(\n",
        "    ventas_totales_sin_dto=('ventas_sin_dto', 'sum'),\n",
        "    ventas_totales_con_dto=('ventas_con_dto', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "impacto_descuentos['impacto'] = impacto_descuentos['ventas_totales_con_dto'] / impacto_descuentos['ventas_totales_sin_dto'] - 1\n",
        "\n",
        "# =============================================================================\n",
        "# 4. Comparación de Precios:\n",
        "# =============================================================================\n",
        "# =============================================================================\n",
        "# ¿Existe variación significativa en los precios de productos similares entre\n",
        "#  las ubicaciones?\n",
        "# =============================================================================\n",
        "ubicaciones = tabla_total['ubicacion'].unique()\n",
        "\n",
        "# Opcion 1\n",
        "\n",
        "# Calcular la media de precios por producto y ubicación\n",
        "tabla_media = tabla_total.pivot_table(index='producto', columns='ubicacion', values='precio', aggfunc='mean')\n",
        "\n",
        "# Restablecer el índice para que 'producto' sea una columna normal\n",
        "tabla_media.reset_index(inplace=True)\n",
        "\n",
        "# Opcion 2\n",
        "\n",
        "ventas_ubicaciones = tabla_total.groupby(['ubicacion','producto']).agg(\n",
        "    media_precio=('precio', 'mean'),\n",
        ").reset_index()\n",
        "\n",
        "# =============================================================================\n",
        "# ¿Qué diferencias estratégicas en precios pueden identificarse entre\n",
        "#  Barcelona, Valencia, Pozuelo, Mallorca y Malasaña?\n",
        "# =============================================================================\n",
        "\n",
        "ubicaciones = tabla_total['local'].unique()\n",
        "\n",
        "\n",
        "# Calcular la media de precios por producto y ubicación\n",
        "tabla_media = tabla_total.pivot_table(index='producto', columns='local', values='precio', aggfunc='mean')\n",
        "\n",
        "# Restablecer el índice para que 'producto' sea una columna normal\n",
        "tabla_media.reset_index(inplace=True)\n",
        "\n",
        "# =============================================================================\n",
        "# 5. Productos Más Vendidos:\n",
        "# =============================================================================\n",
        "# =============================================================================\n",
        "# ¿Cuáles son los productos más vendidos en cada ubicación?\n",
        "# =============================================================================\n",
        "\n",
        "top_ventas_ubicacion = tabla_total.groupby(['local','producto'])['cantidad'].sum().reset_index(name=\"vendidos\").sort_values(by='vendidos', ascending=False)\n",
        "\n",
        "# He creado una función para obtener los x primeros productos más vendidos\n",
        "# en cada ubicación. Creo que esto agilizara la consutla para el estudio de\n",
        "# las ventas.\n",
        "\n",
        "def top_x_productos(x):\n",
        "\n",
        "    top_por_ubicacion = (\n",
        "        top_ventas_ubicacion.groupby('local')\n",
        "        .head(x)  # Seleccionar los primeros 5 por grupo\n",
        "        .reset_index(drop=True)\n",
        "        .sort_values(by='local', ascending=True)\n",
        "    )\n",
        "\n",
        "    return top_por_ubicacion\n",
        "\n",
        "top_1_por_ubicacion = top_x_productos(1)\n",
        "top_5_por_ubicacion = top_x_productos(5)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# ¿Cómo varía la popularidad de los productos a lo largo de diferentes\n",
        "# meses y días en cada ubicación?\n",
        "# =============================================================================\n",
        "\n",
        "tabla_total['mes'] = tabla_total['fecha'].dt.month\n",
        "tabla_total['dia'] = tabla_total['fecha'].dt.day\n",
        "\n",
        "\n",
        "ventas_por_mes_dia = tabla_total.groupby(['local', 'producto', 'mes', 'dia'])['cantidad'].sum().reset_index(name='vendidos')\n",
        "\n",
        "promedio_mensual = ventas_por_mes_dia.groupby(['local', 'producto', 'mes'])['vendidos'].mean().reset_index(name='promedio_mensual')\n",
        "\n",
        "promedio_diario =  ventas_por_mes_dia.groupby(['local', 'producto', 'dia'])['vendidos'].mean().reset_index(name='promedio_diario')\n",
        "\n",
        "variacion_mensual_diaria = (\n",
        "    ventas_por_mes_dia\n",
        "    .merge(promedio_mensual, on=['local', 'producto', 'mes'], how='left')\n",
        "    .merge(promedio_diario, on=['local', 'producto', 'dia'], how='left')\n",
        ")\n",
        "\n",
        "variacion_mensual_diaria['variacion_mensual'] = (\n",
        "    (variacion_mensual_diaria['vendidos'] - variacion_mensual_diaria['promedio_mensual']) /\n",
        "    variacion_mensual_diaria['promedio_mensual']\n",
        ") * 100\n",
        "\n",
        "variacion_mensual_diaria['variacion_diaria'] = (\n",
        "    (variacion_mensual_diaria['vendidos'] - variacion_mensual_diaria['promedio_diario']) /\n",
        "    variacion_mensual_diaria['promedio_diario']\n",
        ") * 100\n",
        "\n",
        "\n",
        "# Ordenar por mayor variación mensual\n",
        "variacion_mensual_top = variacion_mensual_diaria.sort_values(by='variacion_mensual', ascending=False)\n",
        "\n",
        "# Ordenar por mayor variación diaria\n",
        "variacion_diaria_top = variacion_mensual_diaria.sort_values(by='variacion_diaria', ascending=False)\n",
        "\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# 6. Clientes Comunes:\n",
        "# =============================================================================\n",
        "# =============================================================================\n",
        "# ¿Existen clientes que han realizado compras en más de una ubicación?\n",
        "# =============================================================================\n",
        "clientes_local = tabla_total.groupby('cliente')['ubicacion'].nunique().reset_index(name='num_ubicaciones')\n",
        "\n",
        "clientes_m1u = clientes_local.loc[clientes_local[\"num_ubicaciones\"] > 1]\n",
        "\n",
        "# =============================================================================\n",
        "# ¿Cómo contribuyen estos clientes a las ventas totales y cuál es su\n",
        "# comportamiento de compra en diferentes ubicaciones?\n",
        "# =============================================================================\n",
        "\n",
        "lista_clientes_m1u = clientes_m1u['cliente'].tolist()\n",
        "\n",
        "ventas_clientes_m1u = tabla_total[tabla_total[\"cliente\"].isin(lista_clientes_m1u)]\n",
        "\n",
        "suma_ventas_m1u = ventas_clientes_m1u.groupby('cliente')['precio'].sum().reset_index(name='suma_ventas_m1u')\n",
        "\n",
        "suma_ventas_m1u[\"total_ventas\"] = tabla_total[\"precio\"].sum()\n",
        "\n",
        "suma_ventas_m1u[\"porcentaje_ventas_m1u\"] = ((suma_ventas_m1u[\"suma_ventas_m1u\"]/suma_ventas_m1u[\"total_ventas\"]) * 100).round(2)\n",
        "\n",
        "# =============================================================================\n",
        "# 7. Análisis Detallado del Comportamiento de Ventas:\n",
        "# =============================================================================\n",
        "# =============================================================================\n",
        "# ¿Cuál es la duración promedio de una transacción? (Calcula la diferencia\n",
        "#  entre la fecha de creación y la fecha de venta).\n",
        "# =============================================================================\n",
        "\n",
        "#primero verificamos que tanto \"fecha\" como \"fecha de creacion\"\n",
        "#se encuentren en tipo datetime, si es asi realizamos lo siguiente:\n",
        "\n",
        "# Calcular la diferencia entre'fecha creacion' y 'fecha' en horas\n",
        "\n",
        "tabla_total['duracion_transaccion'] = (tabla_total['fecha creacion'] - tabla_total['fecha']).dt.total_seconds() / (60 * 60)  # en horas\n",
        "\n",
        "# =============================================================================\n",
        "# ¿En qué día de la semana se realizan más ventas en promedio?\n",
        "# =============================================================================\n",
        "\n",
        "# primero asigno cada día de la semana a la columna 'fecha'con dayofweek,\n",
        "# lunes = 0 , martes = 1 etc..\n",
        "\n",
        "tabla_total['dia_semana'] = tabla_total['fecha'].dt.dayofweek\n",
        "\n",
        "# contamos el total de ventas por dia\n",
        "ventas_por_dia = tabla_total.groupby('dia_semana').size()\n",
        "\n",
        "# vemos cual es el día de la semana con más ventas en promedio\n",
        "dia_con_mas_ventas = ventas_por_dia.idxmax()\n",
        "\n",
        "## hasta ahi ya tengo lo que me piden pero nose si el quiere que se vea reflejado\n",
        "## en la tabla o asi estaria bien\n",
        "\n",
        "# =============================================================================\n",
        "#¿Cuáles son los meses con las ventas más altas y más bajas?\n",
        "# =============================================================================\n",
        "\n",
        "# Extraer el mes de la columna 'fecha'\n",
        "tabla_total['mes'] = tabla_total['fecha'].dt.month\n",
        "\n",
        "# Sumar las ventas por mes.\n",
        "ventas_por_mes = tabla_total.groupby('mes')['total'].sum()\n",
        "\n",
        "# Identificar el mes con las ventas más altas y más bajas\n",
        "mes_ventas_max = ventas_por_mes.idxmax()\n",
        "mes_ventas_min = ventas_por_mes.idxmin()\n",
        "\n",
        "# =============================================================================\n",
        "# ¿Cuál es el porcentaje de descuento promedio en relación con el precio\n",
        "#  original de los productos?\n",
        "# =============================================================================\n",
        "\n",
        "# Calcular el porcentaje de descuento promedio en comparacion al precio original\n",
        "descuento_promedio = tabla_total['dto. %'].mean()\n",
        "\n",
        "# resultado\n",
        "print(f\"El porcentaje de descuento promedio es: {descuento_promedio:.2f}%\")\n",
        "\n",
        "# =============================================================================\n",
        "# 8. Preguntas adicionales:\n",
        "# =============================================================================\n",
        "# =============================================================================\n",
        "# 8.1 Crear una columna que indique si una venta tuvo un descuento y que\n",
        "# porcentaje de ventas tuvieron descuento\n",
        "# =============================================================================\n",
        "\n",
        "# Crear la nueva columna 'tiene_descuento'\n",
        "tabla_total['tiene_descuento'] = (tabla_total['dto. %'] > 0) | (tabla_total['dto. eur'] > 0)\n",
        "\n",
        "# Calcular el porcentaje de ventas con descuento\n",
        "ventas_con_descuento = tabla_total['tiene_descuento'].sum()\n",
        "len_total = len(tabla_total)\n",
        "porcentaje_con_descuento = (ventas_con_descuento / len_total) * 100\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# 8.2. Crear una columna de ganancia neta restando el costo de los\n",
        "# productos al total\n",
        "# =============================================================================\n",
        "\n",
        "tabla_total['ganancia_neta'] = tabla_total['total'] - tabla_total['precio coste']\n",
        "\n",
        "# =============================================================================\n",
        "# 8.3 Crear una columna que clasifique las ventas como \"Alta\", \"Media\" o\n",
        "# \"Baja\" según el monto total\n",
        "# =============================================================================\n",
        "#Opcion 1\n",
        "tabla_total[\"clasificacion_ventas\"] = pd.cut(tabla_total.total,bins=[tabla_total.total.min(),0,tabla_total.total.mean(),tabla_total.total.max()],\n",
        "                               labels=[\"Baja\",\"Media\",\"Alta\"])\n",
        "\n",
        "#Opcion 2\n",
        "tabla_total[\"clasificacion_ventas\"] = pd.cut(tabla_total.total,bins=[tabla_total.total.min(),tabla_total.total.mean(),450,tabla_total.total.max()],\n",
        "                               labels=[\"Baja\",\"Media\",\"Alta\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Documentación y Presentación del Informe Final:\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Limpieza de datos\n",
        "\n",
        "Tras realizar un análisis preliminar del tipo de variables del dataset con métodos como dtypes, .size, .columns o .info() entre otros, comprobamos cuántas de estas variables tenían datos que debían ser preprocesados para facilitar su posterior análisis. Mostramos la cantidad de datos nulos y los cuantificamos para tomar decisiones sobre qué variables eliminar y cuáles conservar.\n",
        "Posteriormente, realizamos las primeras transformaciones de los datos, limpiando los nombres de las variables con .strip() y poniéndolos todos en minúsculas con .lower. También realizamos un unidecode para eliminar todo tipo de caracteres especiales.\n",
        "En cuanto a la limpieza de nulos, inicialmente iteramos sobre la variable fecha para eliminar las filas con fechas nulas mediante un bucle for. Imputamos el valor \"NO INFO\" para los valores nulos de la variable familia y limpiamos la variable local usando índices. Eliminamos las variables con un alto contenido de valores nulos que no eran relevantes para el análisis, como cod_promoción, cod_descuento y grupo_mayor. Por precaución, creamos un nuevo dataframe con todas esas variables eliminadas, para facilitar el acceso a las mismas en el futuro.\n",
        "\n",
        "---\n",
        "1.\tAnálisis Temporal\n",
        "\n",
        "Limpiamos la variable fecha con el método pd.to_datetime(tabla_total['fecha'], errors='coerce'), asegurándonos de que todos los valores tienen el formato adecuado. Posteriormente, creamos nuevas columnas con los valores de año, mes y día para acceder con mayor facilidad a los datos de fechas.\n",
        "Para obtener el resumen de ventas por día, realizamos un groupby por fecha y local, sumando su total. Hicimos lo mismo a nivel mensual, agrupando esta vez por mes.\n",
        "Con el objetivo de identificar las variaciones estacionales, utilizamos el método pd.cut para segmentar la variable fecha en las cuatro estaciones. Esto nos permitió observar las variaciones a lo largo de las estaciones, agrupando por año y estación.\n",
        "\n",
        "---\n",
        "2. Análisis Geográfico\n",
        "\n",
        "Agrupamos por ubicación y calculamos la suma y la media del total de ventas.\n",
        "Agrupamos también por el número de clientes únicos por ubicación y lo guardamos en una columna.\n",
        "Filtramos por los productos más populares por ubicación usando .size(), lo cual nos da el número de veces que cada producto aparece en cada ubicación.\n",
        "Ordenamos esta información con .sort_values().\n",
        "Finalmente, usamos .idxmax() para obtener la fila completa del producto y ubicación con mayor frecuencia.\n",
        "\n",
        "---\n",
        "3. Análisis de Descuentos\n",
        "\n",
        "Primero realizamos una operación para obtener las ventas con y sin descuento, para posteriormente hacer un .groupby() por ubicación y aplicar una función de agregación que nos permita obtener el total sumado de ambos tipos de ventas en cada lugar.\n",
        "\n",
        "Finalmente, calculamos el porcentaje de ventas totales comparándolo con las ventas totales con descuento.\n",
        "\n",
        "Para identificar los tipos de descuentos más utilizados, aplicamos .size() para contar cuántas filas tuvieron cada descuento y cuantificarlos en una nueva columna llamada \"frecuencia\", ordenada con .sort_values().\n",
        "\n",
        "Después agrupamos por \"cod. descuento\" y usamos .agg() para sumar las ventas con y sin descuento, permitiéndonos calcular el porcentaje de impacto en las ventas totales dividiendo el total con descuento entre el total sin descuento.\n",
        "\n",
        "---\n",
        "4. Comparación de Precios\n",
        "\n",
        "Obtenemos información sobre los valores únicos en la variable ubicación y, posteriormente, usamos el método pivot_table, que nos permite visualizar la información de un vistazo. Filtramos por la columna ubicación y calculamos la media de la columna precio. Podemos realizar un reset_index para recuperar los índices de la columna, aunque en este caso no es necesario.\n",
        "Para realizar el mismo filtrado por local, simplemente modificamos el argumento y obtenemos el resultado: un dataframe con todas las ubicaciones una tras otra.\n",
        "Aunque podríamos realizar la consulta de otro modo usando un groupby, la información se mostraría de una manera mucho menos visual (una ubicación debajo de otra), dificultando mucho más la comparación entre ellas.\n",
        "\n",
        "---\n",
        "5. Productos Más Vendidos\n",
        "\n",
        "\n",
        "Aquí tienes tu texto corregido, Bro, manteniendo la estructura pero con mejor claridad y gramática:\n",
        "\n",
        "Para saber cuáles son los productos más vendidos por ubicación, agrupamos por \"local\" y \"producto\", sumamos la cantidad y ordenamos los valores. Luego, guardamos esta información en una nueva columna llamada \"vendidos\".\n",
        "\n",
        "Con una función sencilla, agrupamos por \"local\", seleccionamos el número del Top X de productos que queremos obtener y los ordenamos por local. Usamos el método .head() para extraer los productos más vendidos en cada ubicación dentro de la variable \"local\".\n",
        "\n",
        "Usando datetime, agrupamos los datos por mes y día, aplicando .sum() para obtener la cantidad total de productos vendidos en cada periodo. Posteriormente, calculamos la media mensual y diaria con .mean(), utilizando la columna \"vendidos\" que creamos anteriormente.\n",
        "\n",
        "Con los datasets resultantes (promedio_mensual y promedio_diario), realizamos un .merge() para unirlos y poder operar con los datos combinados. En este caso, necesitamos calcular la variación mensual y diaria de las ventas, por lo que creamos nuevas columnas donde restamos el total vendido al promedio mensual y lo dividimos entre este mismo. Multiplicándolo por 100, obtenemos el porcentaje de aumento o descenso con respecto al promedio mensual o diario.\n",
        "\n",
        "Finalmente, ordenamos los resultados para visualizar con mayor claridad dónde hubo mayores diferencias.\n",
        "\n",
        "---\n",
        "6. Clientes Comunes\n",
        "\n",
        "Con un .nunique y un .groupby podemos saber cuántos clientes únicos hay en las diferentes ubicaciones. Con esta información, convertimos en lista el dataset usando .to_list, filtramos nuestro dataset original por las ubicaciones donde están estos clientes únicos que han realizado compras en más de una ubicación, y con .isin los seleccionamos.\n",
        "Sumamos el precio por cliente y lo comparamos con el sumatorio total de precios para, de este modo, obtener el porcentaje total de gasto que aportaron al contante final.\n",
        "\n",
        "---\n",
        "\n",
        "7. Análisis Detallado del Comportamiento de Ventas:\n",
        "\n",
        "7.1\n",
        "\n",
        "tabla_copia['duracion_transaccion'] = (tabla_copia['fecha creacion'] - tabla_copia['fecha']).dt.total_seconds() / (60 * 60)\n",
        "\n",
        "1.\t**`tabla_copia['fecha creacion'] - tabla_copia['fecha']`**:      Aquí se están restando dos columnas del DataFrame `tabla_copia`: la fecha de creación (`fecha creacion`) y la fecha de venta (`fecha`). El resultado de esta resta es un **`timedelta`** que contiene la diferencia de tiempo entre las dos fechas.\n",
        "\n",
        "2.\t**`.dt.total_seconds()`**:   \n",
        "   Luego, se usa `.dt.total_seconds()` para convertir esa diferencia en **segundos**. Esto convierte el `timedelta` en un valor numérico que nos da la cantidad total de segundos entre las dos fechas.\n",
        "\n",
        "7.2--------------------------------------------------------------------------\n",
        "\n",
        "1.\t**`tabla_copia['fecha'].dt.dayofweek`**:   \n",
        "   Aquí estamos usando `.dt.dayofweek` para obtener el número que representa el **día de la semana** de la columna `fecha`. El valor devuelto es un entero donde:    - **0** representa lunes    - **1** representa martes    - **6** representa domingo.\n",
        "\n",
        "\n",
        "2.\t**`groupby('dia_semana')`**:   \n",
        "   Agrupamos los datos por la columna `dia_semana`, que contiene los días de la semana. Luego, usamos `.size()` para contar cuántas ventas hubo en cada día de la semana.\n",
        "\n",
        "\n",
        "3.\t**`idxmax()`**:   \n",
        "   Este método nos devuelve el **índice** (en este caso, el día de la semana) del valor máximo en la serie `ventas_por_dia`, es decir, el día de la semana en el que se realizaron más ventas.\n",
        "\n",
        "### **Identificación de los meses con más y menos ventas**\n",
        "\n",
        "```python\n",
        "tabla_copia['mes'] = tabla_copia['fecha'].dt.month\n",
        "```\n",
        "\n",
        "1.\t**`tabla_copia['fecha'].dt.month`**:   \n",
        "   Con `.dt.month`, extraemos el **mes** de la columna `fecha`, que nos da un valor entero entre 1 y 12, representando los meses de enero a diciembre.\n",
        "\n",
        "```python\n",
        "ventas_por_mes = tabla_copia.groupby('mes')['total'].sum()\n",
        "```\n",
        "\n",
        "2.\t**`groupby('mes')`**:   \n",
        "   Agrupamos los datos por mes. Luego, usamos `.sum()` para sumar el valor de las ventas (`total`) de cada mes. Esto nos da el total de ventas de cada mes.\n",
        "\n",
        "```python\n",
        "mes_ventas_max = ventas_por_mes.idxmax()\n",
        "mes_ventas_min = ventas_por_mes.idxmin()\n",
        "```\n",
        "\n",
        "3.\t**`idxmax()` y `idxmin()`**:   \n",
        "-\t`idxmax()` nos da el **mes con las ventas más altas**.\n",
        "-\t`idxmin()` nos da el **mes con las ventas más bajas**.\n",
        "\n",
        " 7.3--------------------------------------------------------------------------\n",
        "\n",
        "1.\t**`tabla_copia['dto. %']`**:   \n",
        "   Accedemos a la columna que contiene el porcentaje de descuento en cada transacción (presumiblemente llamada `dto. %`).\n",
        "\n",
        "2.\t**`.mean()`**:   \n",
        "  Usamos `.mean()` para calcular el **promedio** de los porcentajes de descuento.\n",
        "\n",
        "3.\t**`print()`**:   \n",
        "   Finalmente, imprimimos el resultado del cálculo, mostrando el porcentaje de descuento promedio con dos decimales.\n",
        "\n",
        "---\n",
        "8. Preguntas adicionales:\n",
        "\n",
        "Para saber si una venta tuvo o no un descuento, es sencillo realizar una consulta con dos condiciones en las variables que representan los descuentos “dto. %” y “dto. eur”. En el caso de que una de estas sea mayor que 0, se añadirá a la variable.\n",
        "\n",
        "Para obtener el porcentaje total de ventas que tuvieron descuento, realizamos la suma de todas estas ventas con descuento y hacemos una operación para sacar el porcentaje con el total de registros de ventas del DataFrame, sirviéndonos de la función .len() que nos da esta información.\n",
        "\n",
        "Para obtener el dato de la ganancia neta, únicamente seleccionamos la variable del “total” y la de “precio de coste” y las restamos.\n",
        "\n",
        "Y finalmente, para realizar una segmentación en función de los datos de ventas, usamos la variable “total” para realizar un pd.cut() y segmentar, en este caso, en función del mínimo, la media y el valor máximo de esta columna, asignando la clasificación \"Alta\", \"Media\" o \"Baja\" con respecto a los datos totales de esta variable.\n"
      ],
      "metadata": {
        "id": "UPM2FSCM1_hi"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}